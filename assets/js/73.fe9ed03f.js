(window.webpackJsonp=window.webpackJsonp||[]).push([[73],{415:function(t,s,e){"use strict";e.r(s);var a=e(18),n=Object(a.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"test-organization"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#test-organization"}},[t._v("#")]),t._v(" Test Organization")]),t._v(" "),s("p",[t._v("As mentioned at the start of the chapter, testing is a complex discipline, and different people use different terminology and organization. The Rust community thinks about tests in terms of two main categories: unit tests and integration tests. Unit tests are small and more focused, testing one module in isolation at a time, and can test private interfaces. Integration tests are entirely external to your library and use your code in the same way any other external code would, using only the public interface and potentially exercising multiple modules per test.")]),t._v(" "),s("p",[t._v("Writing both kinds of tests is important to ensure that the pieces of your library are doing what you expect them to, separately and together.")]),t._v(" "),s("h3",{attrs:{id:"unit-tests"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#unit-tests"}},[t._v("#")]),t._v(" Unit Tests")]),t._v(" "),s("p",[t._v("The purpose of unit tests is to test each unit of code in isolation from the rest of the code to quickly pinpoint where code is and isn’t working as expected. You’ll put unit tests in the src directory in each file with the code that they’re testing. The convention is to create a module named tests in each file to contain the test functions and to annotate the module with "),s("code",[t._v("cfg(test)")]),t._v(".")]),t._v(" "),s("h4",{attrs:{id:"the-tests-module-and-cfg-test"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-tests-module-and-cfg-test"}},[t._v("#")]),t._v(" The Tests Module and "),s("code",[t._v("#[cfg(test)]")])]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("#[cfg(test)]")]),t._v(" annotation on the tests module tells Rust to compile and run the test code only when you run cargo test, not when you run cargo build. This saves compile time when you only want to build the library and saves space in the resultant compiled artifact because the tests are not included. You’ll see that because integration tests go in a different directory, they don’t need the "),s("code",[t._v("#[cfg(test)]")]),t._v(" annotation. However, because unit tests go in the same files as the code, you’ll use "),s("code",[t._v("#[cfg(test)]")]),t._v(" to specify that they shouldn’t be included in the compiled result.")]),t._v(" "),s("p",[t._v("Recall that when we generated the new adder project in the first section of this chapter, Cargo generated this code for us:")]),t._v(" "),s("p",[t._v("Filename: src/lib.rs:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pub")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("left"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("u64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" right"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("u64")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("->")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("u64")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    left "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" right\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token attribute attr-name"}},[t._v("#[cfg(test)]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mod")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token module-declaration namespace"}},[t._v("tests")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token attribute attr-name"}},[t._v("#[test]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("it_works")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("assert_eq!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("On the automatically generated tests module, the attribute cfg stands for configuration and tells Rust that the following item should only be included given a certain configuration option. In this case, the configuration option is test, which is provided by Rust for compiling and running tests. By using the cfg attribute, Cargo compiles our test code only if we actively run the tests with "),s("code",[t._v("cargo test")]),t._v(". This includes any helper functions that might be within this module, in addition to the functions annotated with "),s("code",[t._v("#[test]")]),t._v(".")]),t._v(" "),s("h4",{attrs:{id:"testing-private-functions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#testing-private-functions"}},[t._v("#")]),t._v(" Testing Private Functions")]),t._v(" "),s("p",[t._v("There’s debate within the testing community about whether or not private functions should be tested directly, and other languages make it difficult or impossible to test private functions. Regardless of which testing ideology you adhere to, Rust’s privacy rules do allow you to test private functions. Consider the code in Listing 11-12 with the private function internal_adder.")]),t._v(" "),s("p",[t._v("Filename: src/lib.rs:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pub")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("add_two")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("usize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("->")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("usize")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("internal_adder")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("internal_adder")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("left"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("usize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" right"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("usize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("->")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("usize")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    left "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" right\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token attribute attr-name"}},[t._v("#[cfg(test)]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mod")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token module-declaration namespace"}},[t._v("tests")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("super")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token attribute attr-name"}},[t._v("#[test]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("internal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("internal_adder")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("assert_eq!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Listing 11-12: Testing a private function")]),t._v(" "),s("p",[t._v("Note that the internal_adder function is not marked as pub. Tests are just Rust code, and the tests module is just another module. As we discussed in the “Paths for Referring to an Item in the Module Tree” section, items in child modules can use the items in their ancestor modules. In this test, we bring all of the tests module’s parent’s items into scope with "),s("code",[t._v("use super::\\*")]),t._v(", and then the test can call internal_adder. If you don’t think private functions should be tested, there’s nothing in Rust that will compel you to do so.")]),t._v(" "),s("h3",{attrs:{id:"integration-tests"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#integration-tests"}},[t._v("#")]),t._v(" Integration Tests")]),t._v(" "),s("p",[t._v("In Rust, integration tests are entirely external to your library. They use your library in the same way any other code would, which means they can only call functions that are part of your library’s public API. Their purpose is to test whether many parts of your library work together correctly. Units of code that work correctly on their own could have problems when integrated, so test coverage of the integrated code is important as well. To create integration tests, you first need a tests directory.")]),t._v(" "),s("h4",{attrs:{id:"the-tests-directory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-tests-directory"}},[t._v("#")]),t._v(" The tests Directory")]),t._v(" "),s("p",[t._v("We create a tests directory at the top level of our project directory, next to src. Cargo knows to look for integration test files in this directory. We can then make as many test files as we want, and Cargo will compile each of the files as an individual crate.")]),t._v(" "),s("p",[t._v("Let’s create an integration test. With the code in Listing 11-12 still in the src/lib.rs file, make a tests directory, and create a new file named tests/integration_test.rs. Your directory structure should look like this:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[t._v("adder\n├── "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cargo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lock\n├── "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cargo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toml\n├── src\n│   └── lib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rs\n└── tests\n    └── integration_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rs\n")])])]),s("p",[t._v("Enter the code in Listing 11-13 into the tests/integration_test.rs file.")]),t._v(" "),s("p",[t._v("Filename: tests/integration_test.rs:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("adder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),t._v("add_two"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token attribute attr-name"}},[t._v("#[test]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("it_adds_two")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add_two")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("assert_eq!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Listing 11-13: An integration test of a function in the adder crate")]),t._v(" "),s("p",[t._v("Each file in the tests directory is a separate crate, so we need to bring our library into each test crate’s scope. For that reason we add use adder::add_two; at the top of the code, which we didn’t need in the unit tests.")]),t._v(" "),s("p",[t._v("We don’t need to annotate any code in tests/integration_test.rs with "),s("code",[t._v("#[cfg(test)]")]),t._v(". Cargo treats the tests directory specially and compiles files in this directory only when we run "),s("code",[t._v("cargo test")]),t._v(". Run "),s("code",[t._v("cargo test")]),t._v(" now:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[t._v("$ cargo test\n   "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Compiling")]),t._v(" adder v0"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//projects/adder)")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Finished")]),t._v(" `test` profile "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("unoptimized "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" debuginfo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("target")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("31s\n     "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Running")]),t._v(" unittests src"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("lib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rs")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("debug"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("deps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("adder"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("1082c4b063a8fbe6"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" test\ntest "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("tests"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),t._v("internal "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v(" ok\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n\n     "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Running")]),t._v(" tests"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("integration_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rs")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("debug"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("deps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("integration_test"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("1082c4b063a8fbe6"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" test\ntest it_adds_two "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v(" ok\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n\n   "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Doc")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("tests adder\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" tests\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n")])])]),s("p",[t._v("The three sections of output include the unit tests, the integration test, and the doc tests. Note that if any test in a section fails, the following sections will not be run. For example, if a unit test fails, there won’t be any output for integration and doc tests because those tests will only be run if all unit tests are passing.")]),t._v(" "),s("p",[t._v("The first section for the unit tests is the same as we’ve been seeing: one line for each unit test (one named "),s("code",[t._v("internal")]),t._v(" that we added in Listing 11-12) and then a summary line for the unit tests.")]),t._v(" "),s("p",[t._v("The integration tests section starts with the line "),s("code",[t._v("Running tests/integration_test.rs")]),t._v(". Next, there is a line for each test function in that integration test and a summary line for the results of the integration test just before the "),s("code",[t._v("Doc-tests adder")]),t._v(" section starts.")]),t._v(" "),s("p",[t._v("Each integration test file has its own section, so if we add more files in the tests directory, there will be more integration test sections.")]),t._v(" "),s("p",[t._v("We can still run a particular integration test function by specifying the test function’s name as an argument to "),s("code",[t._v("cargo test")]),t._v(". To run all the tests in a particular integration test file, use the "),s("code",[t._v("--test")]),t._v(" argument of "),s("code",[t._v("cargo test")]),t._v(" followed by the name of the file:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[t._v("$ cargo test "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("test integration_test\n   "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Compiling")]),t._v(" adder v0"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//projects/adder)")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Finished")]),t._v(" `test` profile "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("unoptimized "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" debuginfo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("target")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("64s\n     "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Running")]),t._v(" tests"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("integration_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rs")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("debug"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("deps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("integration_test"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("82e7799c1bc62298"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" test\ntest it_adds_two "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v(" ok\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n")])])]),s("p",[t._v("This command runs only the tests in the "),s("code",[t._v("tests/integration_test.rs")]),t._v(" file.")]),t._v(" "),s("h4",{attrs:{id:"submodules-in-integration-tests"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#submodules-in-integration-tests"}},[t._v("#")]),t._v(" Submodules in Integration Tests")]),t._v(" "),s("p",[t._v("As you add more integration tests, you might want to make more files in the tests directory to help organize them; for example, you can group the test functions by the functionality they’re testing. As mentioned earlier, each file in the tests directory is compiled as its own separate crate, which is useful for creating separate scopes to more closely imitate the way end users will be using your crate. However, this means files in the tests directory don’t share the same behavior as files in src do, as you learned in Chapter 7 regarding how to separate code into modules and files.")]),t._v(" "),s("p",[t._v("The different behavior of tests directory files is most noticeable when you have a set of helper functions to use in multiple integration test files and you try to follow the steps in the “Separating Modules into Different Files” section of Chapter 7 to extract them into a common module. For example, if we create tests/common.rs and place a function named setup in it, we can add some code to setup that we want to call from multiple test functions in multiple test files:")]),t._v(" "),s("p",[t._v("Filename: tests/common.rs:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pub")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("setup")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// setup code specific to your library's tests would go here")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("When we run the tests again, we’ll see a new section in the test output for the "),s("code",[t._v("common.rs")]),t._v(" file, even though this file doesn’t contain any test functions nor did we call the "),s("code",[t._v("setup")]),t._v(" function from anywhere:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[t._v("$ cargo test\n   "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Compiling")]),t._v(" adder v0"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//projects/adder)")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Finished")]),t._v(" `test` profile "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("unoptimized "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" debuginfo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("target")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("89s\n     "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Running")]),t._v(" unittests src"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("lib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rs")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("debug"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("deps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("adder"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("92948b65e88960b4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" test\ntest "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("tests"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),t._v("internal "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v(" ok\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n\n     "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Running")]),t._v(" tests"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("common"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rs")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("debug"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("deps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("common"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("92948b65e88960b4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" tests\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n\n     "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Running")]),t._v(" tests"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("integration_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("rs")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("debug"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("deps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("integration_test"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("92948b65e88960b4"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" test\ntest it_adds_two "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("...")]),t._v(" ok\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n\n   "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Doc")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("tests adder\n\nrunning "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" tests\n\ntest result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ok"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" passed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" failed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" ignored"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" measured"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" filtered out"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" finished "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("00s\n")])])]),s("p",[t._v("Having "),s("code",[t._v("common")]),t._v(" appear in the test results with "),s("code",[t._v("running 0 tests")]),t._v(" displayed for it is not what we wanted. We just wanted to share some code with the other integration test files. To avoid having "),s("code",[t._v("common")]),t._v(" appear in the test output, instead of creating "),s("code",[t._v("tests/common.rs")]),t._v(", we’ll create tests/common/mod.rs. The project directory now looks like this:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[t._v("├── "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cargo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lock\n├── "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Cargo")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toml\n├── src\n│   └── lib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rs\n└── tests\n    ├── common\n    │   └── "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mod")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rs\n    └── integration_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rs\n")])])]),s("p",[t._v("This is the older naming convention that Rust also understands that we mentioned in the “Alternate File Paths” section of Chapter 7. Naming the file this way tells Rust not to treat the "),s("code",[t._v("common")]),t._v(" module as an integration test file. When we move the "),s("code",[t._v("setup")]),t._v(" function code into "),s("code",[t._v("tests/common/mod.rs")]),t._v(" and delete the "),s("code",[t._v("tests/common.rs")]),t._v(" file, the section in the test output will no longer appear. Files in subdirectories of the tests directory don’t get compiled as separate crates or have sections in the test output.")]),t._v(" "),s("p",[t._v("After we’ve created "),s("code",[t._v("tests/common/mod.rs")]),t._v(", we can use it from any of the integration test files as a module. Here’s an example of calling the "),s("code",[t._v("setup")]),t._v(" function from the "),s("code",[t._v("it_adds_two")]),t._v(" test in "),s("code",[t._v("tests/integration_test.rs")]),t._v(":")]),t._v(" "),s("p",[t._v("Filename: tests/integration_test.rs:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("adder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),t._v("add_two"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mod")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token module-declaration namespace"}},[t._v("common")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token attribute attr-name"}},[t._v("#[test]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("it_adds_two")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("common"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setup")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("add_two")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("assert_eq!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("Note that the "),s("code",[t._v("mod common")]),t._v("; declaration is the same as the module declaration we demonstrated in Listing 7-21. Then, in the test function, we can call the "),s("code",[t._v("common::setup()")]),t._v("function.")]),t._v(" "),s("h4",{attrs:{id:"integration-tests-for-binary-crates"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#integration-tests-for-binary-crates"}},[t._v("#")]),t._v(" Integration Tests for Binary Crates")]),t._v(" "),s("p",[t._v("If our project is a binary crate that only contains a src/main.rs file and doesn’t have a src/lib.rs file, we can’t create integration tests in the tests directory and bring functions defined in the src/main.rs file into scope with a use statement. Only library crates expose functions that other crates can use; binary crates are meant to be run on their own.")]),t._v(" "),s("p",[t._v("This is one of the reasons Rust projects that provide a binary have a straightforward src/main.rs file that calls logic that lives in the src/lib.rs file. Using that structure, integration tests can test the library crate with "),s("code",[t._v("use")]),t._v(" to make the important functionality available. If the important functionality works, the small amount of code in the src/main.rs file will work as well, and that small amount of code doesn’t need to be tested.")]),t._v(" "),s("h3",{attrs:{id:"summary"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#summary"}},[t._v("#")]),t._v(" Summary")]),t._v(" "),s("p",[t._v("Rust’s testing features provide a way to specify how code should function to ensure it continues to work as you expect, even as you make changes. Unit tests exercise different parts of a library separately and can test private implementation details. Integration tests check that many parts of the library work together correctly, and they use the library’s public API to test the code in the same way external code will use it. Even though Rust’s type system and ownership rules help prevent some kinds of bugs, tests are still important to reduce logic bugs having to do with how your code is expected to behave.")]),t._v(" "),s("p",[t._v("Let’s combine the knowledge you learned in this chapter and in previous chapters to work on a project!")])])}),[],!1,null,null,null);s.default=n.exports}}]);