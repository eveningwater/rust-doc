(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{392:function(t,s,a){"use strict";a.r(s);var n=a(18),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"读取文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#读取文件"}},[t._v("#")]),t._v(" 读取文件")]),t._v(" "),s("p",[t._v("现在我们将添加功能来读取 "),s("code",[t._v("file_path")]),t._v(" 参数中指定的文件。首先，我们需要一个样本文件来测试：我们将使用一个包含少量文本的文件，这些文本分布在多行上，并且有一些重复的单词。示例 12-3 有一首艾米莉·狄金森的诗，这将很好地工作！在项目的根级别创建一个名为 "),s("code",[t._v("poem.txt")]),t._v(' 的文件，并输入诗歌"I\'m Nobody! Who are you?"')]),t._v(" "),s("p",[t._v("Filename: poem.txt:")]),t._v(" "),s("div",{staticClass:"language-text extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("I'm nobody! Who are you?\nAre you nobody, too?\nThen there's a pair of us - don't tell!\nThey'd banish us, you know.\n\nHow dreary to be somebody!\nHow public, like a frog\nTo tell your name the livelong day\nTo an admiring bog!\n")])])]),s("p",[t._v("示例 12-3：艾米莉·狄金森的一首诗是一个很好的测试案例。")]),t._v(" "),s("p",[t._v("文本就位后，编辑 "),s("code",[t._v("src/main.rs")]),t._v(" 并添加代码来读取文件，如示例 12-4 所示。")]),t._v(" "),s("p",[t._v("Filename: src/main.rs:")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("std"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),t._v("env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("use")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("std"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),t._v("fs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("main")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// --snip--")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Vec")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("args")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" query "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" file_path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("println!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Searching for {query}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("println!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"In file {file_path}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" contents "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("fs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")])]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("read_to_string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("expect")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Should have been able to read the file"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("println!")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"With text:\\n{contents}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("示例 12-4：读取由第二个参数指定的文件内容")]),t._v(" "),s("p",[t._v("首先，我们通过 "),s("code",[t._v("use")]),t._v(" 语句引入标准库的相关部分：我们需要 "),s("code",[t._v("std::fs")]),t._v(" 来处理文件。")]),t._v(" "),s("p",[t._v("在 main 中，新语句 "),s("code",[t._v("fs::read_to_string")]),t._v(" 接受 file_path，打开该文件，并返回一个类型为 "),s("code",[t._v("std::io::Result<String>")]),t._v(" 的值，其中包含文件的内容。")]),t._v(" "),s("p",[t._v("之后，我们再次添加一个临时的 println! 语句，在读取文件后打印 contents 的值，这样我们可以检查程序到目前为止是否正常工作。")]),t._v(" "),s("p",[t._v("让我们用任意字符串作为第一个命令行参数（因为我们还没有实现搜索部分）和 poem.txt 文件作为第二个参数来运行这段代码：")]),t._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[t._v("$ cargo run "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" the poem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("txt\n   "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Compiling")]),t._v(" minigrep v0"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//projects/minigrep)")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Finished")]),t._v(" `dev` profile "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("unoptimized "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" debuginfo"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("target")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("0s\n     "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Running")]),t._v(" `target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("debug"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("minigrep the poem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("txt`\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Searching")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("In")]),t._v(" file poem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("txt\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("With")]),t._v(" text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("I")]),s("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'m")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("nobody!")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Who")]),t._v(" are you"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Are")]),t._v(" you nobody"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" too"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Then")]),t._v(" there"),s("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'s")]),t._v(" a pair of us "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" don"),s("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'t")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("tell!")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("They")]),s("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'d")]),t._v(" banish us"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" you know"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("How")]),t._v(" dreary to be "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("somebody!")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("How")]),t._v(" public"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" like a frog\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("To")]),t._v(" tell your name the livelong day\n"),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("To")]),t._v(" an admiring "),s("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("bog!")]),t._v("\n")])])]),s("p",[t._v("太好了！代码读取并打印了文件的内容。但是代码有一些缺陷。目前，"),s("code",[t._v("main")]),t._v(" 函数有多个职责：通常，如果每个函数只负责一个想法，函数会更清晰，更容易维护。另一个问题是我们没有很好地处理错误。程序仍然很小，所以这些缺陷不是大问题，但随着程序的增长，干净地修复它们将变得更加困难。在开发程序时尽早开始重构是一个好习惯，因为重构较小的代码量要容易得多。接下来我们将做这个。")])])}),[],!1,null,null,null);s.default=e.exports}}]);